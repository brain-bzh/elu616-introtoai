{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Artificial Intelligence - TP2 - April 19th 2018 \n",
    "--\n",
    "\n",
    "At the end of this session, you will be able to : \n",
    "- Perform basic unsupervised learning tasks using sklearn\n",
    "- Apply unsupervised learning on PyRat datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA,MiniBatchDictionaryLearning,DictionaryLearning\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits dataset\n",
    "\n",
    "For this TP we are going to be using the DIGITS dataset. The first thing we are going to do is load the dataset. \n",
    "\n",
    "As this is <b>unsupervised</b> we will mostly ignore y (it will only be used for visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_digits,y_digits = load_digits(n_class=10,return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(3,10,3*i+1)\n",
    "    \n",
    "    #pick a random digit in the current category     \n",
    "    curX = x_digits[y_digits==i]    \n",
    "    r=np.random.randint(curX.shape[0])\n",
    "    curim = curX[r,:].reshape((8,8))\n",
    "    \n",
    "    plt.imshow(curim,cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,10,3*i+2)\n",
    "    #pick a random digit in the current category     \n",
    "    curX = x_digits[y_digits==i]    \n",
    "    r=np.random.randint(curX.shape[0])\n",
    "    curim = curX[r,:].reshape((8,8))\n",
    "    \n",
    "    plt.imshow(curim,cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(3,10,3*i+3)\n",
    "    #pick a random digit in the current category     \n",
    "    curX = x_digits[y_digits==i]    \n",
    "    r=np.random.randint(curX.shape[0])\n",
    "    curim = curX[r,:].reshape((8,8))\n",
    "    \n",
    "    plt.imshow(curim,cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "Using sklearn we are going to perform K-means clustering with $10$ clusters. As we did in the last TP we will instantiate an object of the class [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), with n_clusters=10 and random_state=0(so that you results are consistent with ours).\n",
    "\n",
    "You then should fit the model to the training data (without passing the y as this is a nonsupervised model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELL TO COMPLETE, create object kmeans from class KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to visualize the centroids of the $10$ clusters. First we have to get the center of each cluster. \n",
    "\n",
    "This will be done by using the attribute cluster\\_centers\\_ from the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CELL TO COMPLETE, put the cluster centers in variable centroids\n",
    "centroids = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "for i,curcen in enumerate(centroids):\n",
    "    \n",
    "    plt.subplot(2,5,i+1)\n",
    "    im_cen = curcen.reshape((8,8))\n",
    "    plt.imshow(im_cen,cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to take a look in our reconstructions using our KMeans model.\n",
    "\n",
    "First we take a sample from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Pick a few random examples \n",
    "whichex = np.random.randint(low=0,high=100,size=1) \n",
    "\n",
    "X_samp = np.concatenate([x_digits[y_digits==i][whichex] for i in range(10)])\n",
    "\n",
    "X_quant = kmeans.transform(X_samp)\n",
    "\n",
    "labels = np.argmin(X_quant,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CELL TO COMPLETE use the transform method from the kmeans object and the argmin method from class numpy\n",
    "### to generate an array containing the closest centroid to the samples \n",
    "### and another array to store the error of reconstructing the samples \n",
    "\n",
    "X_errors = \n",
    "closest_centroids =   #Array containing the closest centroid (argmin of error) to the samples\n",
    "best_errors =  #Array containing the minimal error for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i,(im,im_cen,error) in enumerate(zip(X_samp,closest_centroids,best_errors)):\n",
    "        \n",
    "    plt.subplot(4,6,1+2*i)\n",
    "    plt.imshow(im.reshape(8,8),cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"Original\")\n",
    "    \n",
    "    plt.subplot(4,6,2+2*i)\n",
    "    plt.imshow(im_cen.reshape(8,8),cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"Reconstruction with error %.2E\"%error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the elbow method with inertia, by generating KMeans with clusters ranging from 1 to 99, using random state = 0. Inertia is stored in [inertia\\_](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "inertias = []\n",
    "nclust = range(1,100)\n",
    "### CELL TO COMPLETE, generate a KMeans model with varying n_clusters, fit it to the data \n",
    "### and add its inertia to the inertia list\n",
    "for i in tqdm.tqdm(nclust):\n",
    "    #INSERT CODE HERE\n",
    "plt.plot(nclust,inertias)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Dictionary Learning  on Digits\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to pass to dictionary learning. The first thing is to generate a model using [MiniBatchDictionaryLearning](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.html). MiniBatch here means that the method is trained using only a part of the dataset at each time, which helps immensely with the scaling of the method to bigger and wider datasets, but does not guarantee a performance as good as the normal method (where the method see all the dataset at the same time).\n",
    "\n",
    "Use n_components=$16$, random_state=$0$ and verbose = $10$ to instantiate your object. \n",
    "\n",
    "The method [fit_transform](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.html#sklearn.decomposition.MiniBatchDictionaryLearning.fit_transform) is more useful than fit in this case, as it returns the code generated by the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL TO COMPLETE\n",
    "dictlearn = #Instantiate a MiniBatchDictionaryLearning\n",
    "code = #Get the code from fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now retrieve each of the components of the dictionary, and plot them so we can visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = dictlearn.components_\n",
    "fig,axis = plt.subplots(4,4)\n",
    "for i,d in enumerate(components):\n",
    "    ax = axis[i//4][i%4]\n",
    "    ax.imshow(d.reshape((8,8)),cmap=plt.cm.gray,vmin=np.min(components),vmax=np.max(components))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the structure of the digits was kept by the components, which means that the digits are always centered and that the rest is a uniform background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to generate some reconstructions, so first we are going to generate some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whichex = np.random.randint(low=0,high=100,size=1) \n",
    "samples = list()\n",
    "indexes = list()\n",
    "for i in range(10):\n",
    "    index = np.where(y_digits==i)[0][whichex]\n",
    "    samples.append(x_digits[index])\n",
    "    indexes.append(index)\n",
    "X_samp = np.concatenate(samples)\n",
    "indexes = np.array(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will use the codes obtained using the dictionary and the indexes used to extract the samples to reconstruct the data by using [np.dot]() function to perform matrix multiplication between the sample code and the components from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CELL TO COMPLETE, generate the reconstructions array using code, indexes and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for plot_index,(digit,reconstruction) in enumerate(zip(X_samp,reconstructions)):\n",
    "    plt.subplot(2,10,plot_index*2+1)\n",
    "\n",
    "    plt.imshow(digit.reshape((8,8)),cmap=plt.cm.gray,vmin=x_digits.min(),vmax=x_digits.max())\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('$x$')\n",
    "        \n",
    "    plt.subplot(2,10,plot_index*2+2)\n",
    "    plt.imshow(reconstruction.reshape((8,8)),cmap=plt.cm.gray,vmin=reconstructions.min(),vmax=reconstructions.max())\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    error = np.sum((reconstruction-digit)**2)\n",
    "    plt.title('${\\~x}$, error %.2E' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of manifold learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of the importance of manifold learning, we train a TSNE model and plot the 2D visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "unsup = TSNE(random_state = 0)\n",
    "examples = unsup.fit_transform(x_digits)\n",
    "plt.scatter(examples[:,0],examples[:,1],c=y_digits)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning on pyrat games\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn. Perform the same analysis we did in the digits dataset on the pyrat dataset you generated for TP1. We are going to be concentrating ourselves only in the games that the python lost (i.e y < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CELL TO COMPLETE, load the dataset and stock only the games the python lost in x and y\n",
    "x = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a few configurations of the pyrat dataset. In the first TP (TP0) we made a mistake of representing the labyrinth as (15,21) instead of (21,15). Another mistake we made was not inverting the yaxis, which made that not only our labyrinth was not in the correct aspect ratio it was also inverted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afew = 5\n",
    "for i in range(afew):\n",
    "    ind = np.random.randint(x.shape[0])\n",
    "    plt.imshow(x[ind].reshape((21,15)))\n",
    "    plt.title('Result : %d' % y[ind])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean representation of losses\n",
    "\n",
    "Do the same experiment as of the end of TP0 by showing the mean representation of the games the python didn't win. This time use the correct values for the aspect ratio of the labyrinth and the correct orientation of the y_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELL TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do a visualization of the cluster centroids and reconstructions as we did with digits. Finally try to find the best k by testing different values of n_clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CELL TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary Learning on PyRat Games \n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a MiniBatchDictionaryLearning model of the pyrat dataset. Show the components, the reconstructions and the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try to analyse the data you have, what are the characteristics that you could find in the games where the python lost? You should now carry on with the analysis on your P2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
