{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Artificial Intelligence - TP4 - November 8th 2018\n",
    "--\n",
    "At the end of this session, you will be able to deal with : \n",
    "- Small sample size problem\n",
    "- Imbalanced dataset\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Small sample size problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we want you to analyze the effect of the number of features with respect to the number of samples. \n",
    "\n",
    "We will use the make_classification function from sklearn datasets.  \n",
    "\n",
    "Use the following parameters :\n",
    "- make_classification(n_samples=1000,n_features=var, n_repeated=0, n_redundant=0,n_informative=2, random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "and study the effect of varying n_features. \n",
    "\n",
    "In order to have robust estimate, perform many (eg 20) tests for each value of n_features. \n",
    "\n",
    "\n",
    "What you can notice when the number of samples is less than the number of features ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "data,labels=make_classification(n_samples=1000,n_features=2000, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good solution to overcome the small sample size problem is using different techniques of feature extraction, such as, PCA, ICA, NNMF, ect. Thus, the number of features of the samples will be reduced to the number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second part, we want you to analyze the effect of the imbalenced dataset on the classification metrics, as shown in Pyrat datasets. \n",
    "\n",
    "You could use also make_classification function from sklearn datasets to build an imbalenced dataset\n",
    "Use the following parameters :\n",
    "- make_classification(n_samples=1000,n_features=50,weights=[0.2,0.3,0.5], n_classes=3, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "and study the effect of the imbalenced dataset on the classification metrics, such as, precision, recall, ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation of confusion matrix for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation of confusion matrix for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions:\n",
    "### 1- Down-sample Majority Classes\n",
    "A widely adopted technique for dealing with highly unbalanced datasets is Down-sampling which involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the class 0 is the minority class in our case so we need to resample the remaining classes samples according to this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making classification analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Use  the imblearn library\n",
    "imbalanced-learn is a python package offering a number of re-sampling techniques commonly used in datasets showing strong between-class imbalance. It is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n",
    "for further details: https://github.com/scikit-learn-contrib/imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
